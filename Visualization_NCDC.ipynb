{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NCDC Spatial Distribution\n",
    "\n",
    "In previous tutorial, students can access NCDC weather data by cdo_api_py module. We learned how to download precipitation data within a given extent boundary. \n",
    "\n",
    "\n",
    "In this tutorial, the statistics of NCDC daily precipitation data is presented by color mapping and changing marker size across the whole Indiana.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cdo_api_py import Client\n",
    "import pandas as pd\n",
    "import datetime\n",
    "# token for accessing the NCDC server\n",
    "token = \"<Your Token>\"# be sure not to share your token publicly\n",
    "# Client helps you access the NCDC database with your token\n",
    "my_client = Client(token, default_units=\"None\", default_limit=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get raw dataframe of Stations in Indiana\n",
    "\n",
    "Use the function learned in previous tutorial to download multiple stations in the give extent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code to get stations in the given extent in tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Precipitation Dataset\n",
    "There are hundreds NCDC weather stations in Indiana. However, many stations have low datacoverage. \n",
    "\n",
    "Our task in this part is to keep the dataset with sufficient observation (>95% datacoverage). Our list of stations contains stations in other state. Therefore, we have to get rid of those stations as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropind = []\n",
    "# Drop station without enough date of observation\n",
    "for i in range(len(stations.maxdate)):\n",
    "    # get max and min date of each station\n",
    "    date_str = stations.maxdate[i]\n",
    "    date_str_min= stations.mindate[i]\n",
    "    # transfer string to datetime\n",
    "    datelast = datetime.datetime.strptime(date_str, '%Y-%m-%d')\n",
    "    datefirst= datetime.datetime.strptime(date_str_min, '%Y-%m-%d')\n",
    "    # get the position of stations with insufficient daily data\n",
    "    if datelast-enddate < datetime.timedelta(days=0):\n",
    "        dropind.append(i)\n",
    "    elif datefirst-startdate > datetime.timedelta(days=0):\n",
    "        dropind.append(i)        \n",
    "# delete stations without enough time length\n",
    "stations = stations.drop(stations.index[dropind])\n",
    "stations_raw= stations\n",
    "\n",
    "# Get names of indexes for which datacoverage less than 0.95\n",
    "indexNames = stations[ stations['datacoverage'] < 0.95 ].index\n",
    "# Delete these row indexes from dataFrame\n",
    "stations.drop(indexNames , inplace=True)\n",
    "\n",
    "# other gages with available data less than 0.95\n",
    "# this list can be obtained after downloading all the datasets  \n",
    "Insuff_gage = ['GHCND:US1INBN0010', 'GHCND:US1INBW0010',\n",
    "                 'GHCND:US1INCW0003', 'GHCND:US1INLK0046',\n",
    "                 'GHCND:US1INMN0007', 'GHCND:US1INMT0001',\n",
    "                 'GHCND:US1INPS0001', 'GHCND:US1KYBT0001',\n",
    "                 'GHCND:USC00116558', 'GHCND:USC00121873',\n",
    "                 'GHCND:USC00122041', 'GHCND:USC00124244',\n",
    "                 'GHCND:USC00126801']\n",
    "# get rid of the stations in list above\n",
    "# Get the final station list for downloading\n",
    "stations_IN = stations[~stations['id'].isin(Insuff_gage)]\n",
    "# get rid of the stations in other states\n",
    "other_state = []\n",
    "for i in stations_IN.index:\n",
    "    if stations_IN['name'][i][-5:] != 'IN US':\n",
    "        other_state.append(i)\n",
    "stations_IN.drop(other_state , inplace=True)\n",
    "# list first 20 stations to see if there is something wrong in the dataframe\n",
    "stations_IN.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from the NCDC client\n",
    "i = 0\n",
    "for rowid, station in stations_IN.iterrows(): \n",
    "    # try downloading due to some unaccessible sites of database\n",
    "    try:\n",
    "        station_data = my_client.get_data_by_station(\n",
    "                        datasetid=datasetid,\n",
    "                        stationid=station['id'],\n",
    "                        startdate=startdate,\n",
    "                        enddate=enddate,\n",
    "                        return_dataframe=True,\n",
    "                        include_station_meta=True)\n",
    "        # set datetime to index\n",
    "        station_data.set_index(pd.to_datetime(station_data['date']), inplace =True)\n",
    "        # Drop all rows except for rainfall\n",
    "        Rainfall_day = station_data.filter(['PRCP'])\n",
    "        Rainfall_day = Rainfall_day.rename(columns={\"PRCP\": station['id']})\n",
    "        # Merge the dataframe of rainfall from each station\n",
    "        if i ==0:\n",
    "            merged= Rainfall_day\n",
    "        else:\n",
    "            merged =pd.merge(merged,Rainfall_day ,how='outer', left_index=True, right_index=True)\n",
    "        i +=1\n",
    "    # print the id of broken dataset\n",
    "    except:\n",
    "        print(station['id'])\n",
    "# The unit of rainfall is tenth of mm\n",
    "# Get the final rainfall dataset\n",
    "GHCN_IN  = merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of maximum precipitation\n",
    "\n",
    "Use describe function to generate statistics of precipiation dataset. \n",
    "\n",
    "Drop the nan value of Describe_IN after append lat, long of stations to get a clean dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# There is a simple way to get statistics of dataframe \n",
    "Describe_IN = GHCN_IN.describe()\n",
    "Describe_IN\n",
    "# get lat, long values from stations dataframe\n",
    "stations_lat = stations.pivot(columns='id', index = 'elevationUnit', values='latitude')\n",
    "stations_long= stations.pivot(columns='id', index = 'elevationUnit', values='longitude')\n",
    "# rename the index from meter to latitude and longitude\n",
    "lat_IN  = stations_lat.rename(index={'METERS': 'latitude'})\n",
    "long_IN = stations_long.rename(index={'METERS': 'longitude'})\n",
    "# append lat, long dataframe to the statistics of all stations\n",
    "Describe_IN = Describe_IN.append(lat_IN)\n",
    "Describe_IN = Describe_IN.append(long_IN)\n",
    "# show the statistics of stations in Indiana\n",
    "Describe_IN = Describe_IN.T\n",
    "Describe_IN = Describe_IN.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Mapping\n",
    "Color mapping maximum precipitation can have different color bar. In this script, 'jet' is the main cmap label and is the classic color bar from matlab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the font size\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "# create scatter plot of precipitation with color mapping of maximum values\n",
    "fig, ax = plt.subplots()\n",
    "Describe_IN.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", c='max', cmap=\"viridis\",title='Max Precipitation in Indiana 2019', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code to get rid of the outlier and draw the scatter plot with color mapping of maximum precipitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marker Size\n",
    "Apply marker size to the maximum precipitation values. \n",
    "\n",
    "The formula of marker size can be changed to linear or exponential. It all depends on how you want to present your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 15})\n",
    "Max_less = Describe_IN[Describe_IN['max']<2000]\n",
    "# set up the size of maximum precipitation value\n",
    "# we choose power of 5 to show a more obvious difference between data points\n",
    "# remove the outlier\n",
    "s = [5**(Max_less['max'][i]/Max_less['max'].mean()*2) for i in range(Max_less.shape[0])]\n",
    "Max_less.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", s=s,title='Max Precipitation in Indiana 2019')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the stations shows much larger maximum among others\n",
    "Describe_IN[Describe_IN['max']>2000]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:qgis]",
   "language": "python",
   "name": "conda-env-qgis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
